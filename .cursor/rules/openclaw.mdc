---
description: OpenClaw integration protocol and conventions
globs: ["src/lucy/core/**/*.py"]
alwaysApply: false
---

# OpenClaw Integration Protocol

## Gateway Access
- All LLM calls route through `src/lucy/core/openclaw.py` — the `OpenClawClient` class.
- Gateway base URL and API key come from `settings.openclaw_base_url` and `settings.openclaw_api_key`.
- Uses the OpenAI-compatible `/v1/chat/completions` endpoint.

## Health Check
- On application startup, perform an OpenClaw gateway health check.
- If the gateway is unreachable, fail fast with a clear error.

## Code Execution (Sandbox)
- OpenClaw provides Docker-based code execution via the `exec` tool.
- Lucy can write and execute Python scripts in a sandboxed `/work` directory.
- Scripts persist across calls within the same session.
- Use code execution to ground facts — never generate data from text alone.

## System Prompt Assembly
- System prompt is built in `src/lucy/core/prompt.py` by combining:
  1. `assets/SOUL.md` — personality and tone
  2. `assets/SYSTEM_PROMPT.md` — structured instructions (skills, rules, approach)
  3. Dynamic skill descriptions from the workspace
  4. Composio meta-tool definitions
- The assembled prompt is passed as the system message.

## Error Handling
- 5xx errors: retry once after 2 seconds via tenacity, then surface to user.
- 4xx errors: log the full request/response, do not retry.
- Never expose raw OpenClaw error payloads to Slack users.
